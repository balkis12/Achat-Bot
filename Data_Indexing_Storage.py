from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from Data_Ingestion import load_data_from_mongodb

def build_faiss_index(persist_path="faiss_index"):
    print("ğŸ“¥ Chargement des documents depuis MongoDB...")
    documents = load_data_from_mongodb(split_chunks=True)
    
    if not documents:
        print("âŒ Aucun document trouvÃ© !")
        return
    
    print(f"âœ… {len(documents)} documents chargÃ©s.")
    
    # ğŸ” GÃ©nÃ©ration des embeddings avec LaBSE 
    print("ğŸ” GÃ©nÃ©ration des embeddings avec LaBSE...")
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/LaBSE")
    
    print("ğŸ“¦ Construction de l'index FAISS...")
    db = FAISS.from_documents(documents, embeddings)
    
    # ğŸ’¾ Sauvegarde de l'index FAISS
    print("ğŸ’¾ Sauvegarde de l'index FAISS...")
    db.save_local(persist_path)
    
    print(f"âœ… FAISS index sauvegardÃ© localement dans : {persist_path}")

def load_faiss_index(persist_path="faiss_index"):
    print("ğŸ”„ Chargement de l'index FAISS...")
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/LaBSE")
    db = FAISS.load_local(persist_path, embeddings, allow_dangerous_deserialization=True)
    return db

if __name__ == "__main__":
    build_faiss_index()


