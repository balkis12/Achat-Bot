from pymongo import MongoClient
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

def clean_keys(doc):
    """Supprime les espaces autour des cl√©s d'un document."""
    return {k.strip(): v for k, v in doc.items()}

def clean_text(text):
    """Supprime les nouvelles lignes et les espaces multiples dans un texte."""
    if text is None:
        return "Inconnu"
    return ' '.join(text.strip().split())

def load_data_from_mongodb(split_chunks=True):
    # Connexion √† MongoDB
    try:
        client = MongoClient("mongodb://localhost:27017/")
        db = client["achat_db"]
        print("‚úÖ Connexion √† MongoDB r√©ussie !")
    except Exception as e:
        print(f"‚ùå Erreur de connexion √† MongoDB : {e}")
        return []

    collection_data = db["data"]
    collection_model = db["models"]

    # Compter les documents dans la collection models
    model_count = collection_model.count_documents({})
    print(f"Nombre de documents dans la collection 'models' : {model_count}")

    documents_data = collection_data.find()
    document_count = collection_data.count_documents({})

    if document_count == 0:
        print("‚ùå La collection 'data' est vide.")
        return []

    raw_docs = []
    problematic_docs = []

    for i, doc in enumerate(documents_data):
        doc = clean_keys(doc)  # Nettoyer les cl√©s

        fournisseur = clean_text(doc.get("Nom Fournisseur", None))
        article = clean_text(doc.get("Article", None))
        taux_conformite = doc.get("Taux de conformit√© (%)", "N/A")
        taux_respect = doc.get("Taux de Respect (%)", "N/A")
        score = doc.get("Score", "N/A")
        categorie = doc.get("Cat√©gorie", "Inconnu")
        cout_unitaire = doc.get("Co√ªt unitaire", "N/A")

        # üÜï Ajout des m√©tadonn√©es essentielles
        metadata = {
            "source": "MongoDB",
            "doc_id": str(i),
            "Article": article,  # üìå Champ critique pour RAGAS
            "Cat√©gorie": categorie,  # üìå Champ critique pour RAGAS
            "Fournisseur": fournisseur  # üìå Champ critique pour RAGAS
        }

        if fournisseur == "Inconnu" or article == "Inconnu":
            problematic_docs.append({
                "doc_index": i,
                "doc": doc,
                "error": "Missing Nom Fournisseur or Article"
            })
            continue

        article_fournisseur_key = f"{article} - {fournisseur}"
        prediction_doc = collection_model.find_one({"Article_Fournisseur": article_fournisseur_key})
        quantite_predite = prediction_doc.get("Quantit√©_Pr√©dite", "Inconnue") if prediction_doc else "Inconnue"

        text = f"""
üì¶ Fournisseur : {fournisseur}
üè∑Ô∏è Article : {article}
‚úÖ Taux de conformit√© : {taux_conformite}
‚è±Ô∏è Taux de respect des d√©lais : {taux_respect}
üßÆ Score global : {score}
üóÇÔ∏è Cat√©gorie : {categorie}
üí∏ Co√ªt unitaire moyen : {cout_unitaire} DT
üìä Quantit√© Pr√©dite : {quantite_predite}
"""

        raw_docs.append(Document(
            page_content=text.strip(),
            metadata=metadata  # üì¶ Maintenant avec m√©tadonn√©es essentielles
        ))

    print(f"‚úÖ Nombre de documents ajout√©s √† raw_docs : {len(raw_docs)}")
    print(f"‚ö†Ô∏è Nombre de documents probl√©matiques : {len(problematic_docs)}")

    # Save problematic documents
    with open("problematic_ingestion_docs.txt", "w", encoding="utf-8") as f:
        for prob in problematic_docs:
            f.write(f"Document {prob['doc_index']}:\n")
            f.write(f"Content: {prob['doc']}\n")
            f.write(f"Error: {prob['error']}\n")
            f.write("-" * 50 + "\n")

    if not split_chunks:
        return raw_docs

    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    split_docs = splitter.split_documents(raw_docs)
    return split_docs

if __name__ == "__main__":
    documents = load_data_from_mongodb()
    print(f"Documents charg√©s : {len(documents)}")
    if documents:
        print("Exemple de document charg√© :")
        print(documents[0].page_content)
















